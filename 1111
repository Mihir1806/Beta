import requests
from bs4 import BeautifulSoup
import pandas as pd
import os

# URL of the FEDAI Revaluation Rates page
url = "https://fedai.org.in/RevaluationRates.aspx?Cid=1&SCid=0"
base_url = "https://fedai.org.in"

# Fetch the page content
response = requests.get(url)
soup = BeautifulSoup(response.text, "html.parser")

# Find the table rows containing revaluation data
table_rows = soup.find_all("tr")[1:]  # Skip header row

# Parse the rows
data = []
for row in table_rows:
    cells = row.find_all("td")
    if len(cells) >= 2:
        date_time = cells[0].text.strip()
        link_tag = cells[1].find("a")
        label = link_tag.text.strip() if link_tag else cells[1].text.strip()
        href = link_tag['href'] if link_tag and link_tag.has_attr('href') else None
        full_url = base_url + href if href else None
        data.append({
            "Date & Time": date_time,
            "Label": label,
            "Excel URL": full_url
        })

# Convert to DataFrame
df = pd.DataFrame(data)

# Show the scraped table
print(df)

# Optional: Download Excel files to a folder
download_folder = "fedai_excels"
os.makedirs(download_folder, exist_ok=True)

for index, row in df.iterrows():
    if row["Excel URL"]:
        file_name = f"{row['Label'].replace(' ', '_').replace('/', '-')}.xlsx"
        file_path = os.path.join(download_folder, file_name)
        file_response = requests.get(row["Excel URL"])
        with open(file_path, "wb") as f:
            f.write(file_response.content)
        print(f"Downloaded: {file_name}")